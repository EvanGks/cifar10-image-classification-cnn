{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0265cf3",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNN) for Image Classification with CIFAR-10\n",
    "\n",
    "This notebook demonstrates how to build and train a Convolutional Neural Network (CNN) for image classification using the CIFAR-10 dataset. We will use Keras and TensorFlow for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### What are CNNs?\n",
    "Convolutional Neural Networks (CNNs) are a type of deep learning model specifically designed for processing data with a grid-like topology, such as images.  They are inspired by the biological visual cortex.  Key components include:\n",
    "\n",
    "- **Convolutional Layers:**  Apply filters (kernels) to the input image to extract features.  Each filter detects a specific pattern (e.g., edges, corners).\n",
    "- **Pooling Layers:** Reduce the spatial dimensions of the feature maps, making the network more robust to variations in the position of features and reducing computational cost.  Common types include max pooling and average pooling.\n",
    "- **Fully Connected (Dense) Layers:**  Learn non-linear combinations of the high-level features extracted by the convolutional layers.  These layers are typically used for classification.\n",
    "\n",
    "CNNs are highly effective for image classification because they can automatically learn hierarchical representations of features, from low-level (edges) to high-level (objects).\n",
    "\n",
    "### CIFAR-10 Dataset\n",
    "In image classification, CNNs learn to categorize images into predefined classes. This project demonstrates image classification using CNNs with the CIFAR-10 dataset. CIFAR-10 is a widely used dataset in computer vision, consisting of 60,000 32x32 color images in 10 classes, with 6,000 images per class. The classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. There are 50,000 training images and 10,000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# For evaluation: confusion matrix and classification report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "This section covers loading the CIFAR-10 dataset, preprocessing the images, and splitting the data into training, validation, and test sets.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "*   **Load CIFAR-10 Dataset:** Keras provides a convenient function to load the CIFAR-10 dataset directly.\n",
    "*   **Normalize Pixel Values:** Pixel values are normalized to the range [0, 1] by dividing by 255. This helps in faster convergence during training.\n",
    "*   **One-Hot Encode Labels:** Class labels are converted to a one-hot encoded format. For example, if there are 10 classes, a label '3' will be converted to a vector of length 10 with all zeros except for a '1' at the 3rd index.\n",
    "*   **Split into Training, Validation, and Test Sets:** The dataset is split into training, validation, and test sets. The validation set is used during training to monitor the model's performance on unseen data and to tune hyperparameters. The test set is used to evaluate the final model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Split the original training set into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Training set shape:', x_train.shape, y_train.shape)\n",
    "print('Validation set shape:', x_val.shape, y_val.shape)\n",
    "print('Test set shape:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c600156",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "To improve the model's generalization and robustness, we apply data augmentation to the training images. Data augmentation artificially increases the diversity of the training set by applying random transformations such as rotations, shifts, and horizontal flips. This helps the model learn to recognize objects in a wider variety of conditions and reduces overfitting.\n",
    "\n",
    "**Augmentation techniques used:**\n",
    "- Random rotation (up to 15 degrees)\n",
    "- Random horizontal and vertical shifts (up to 10% of image size)\n",
    "- Random horizontal flips\n",
    "\n",
    "These augmentations are applied in real-time during training using Keras' `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "Here, we define the architecture of our CNN model using Keras Sequential API. The model consists of several layers:\n",
    "\n",
    "*   **Sequential Model:** A linear stack of layers that allows us to build the CNN model layer by layer.\n",
    "*   **L2 Regularization:** L2 regularization (weight decay) is applied to all convolutional and dense layers to further reduce overfitting by penalizing large weights.\n",
    "\n",
    "*   **Convolutional Layers (Conv2D):** These layers are the core building blocks of CNNs. They apply filters to the input image to extract features. We use `ReLU` (Rectified Linear Unit) activation function for non-linearity.\n",
    "*   **MaxPooling Layers (MaxPooling2D):** These layers reduce the spatial dimensions of the feature maps, reducing the number of parameters and computation in the network, and also help to control overfitting.\n",
    "*   **Flatten Layer:** This layer flattens the 2D feature maps into a 1D vector, which can be fed into fully connected (Dense) layers.\n",
    "*   **Dense Layers:** These are fully connected layers. The final Dense layer has `softmax` activation to output probabilities for each class.\n",
    "*   **Batch Normalization Layers:** These layers normalize the inputs of each layer so that they have a mean of 0 and a variance of 1, which helps stabilize and accelerate the learning process by reducing internal covariate shift.\n",
    "*   **Dropout Layers:** These layers randomly deactivate a fraction of neurons during training to help prevent overfitting and improve the model's generalization performance.\n",
    "\n",
    "The model architecture is designed to progressively learn more complex features from the input images as we go deeper into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    l2_reg = regularizers.l2(1e-4)\n",
    "    \n",
    "    # First Convolutional Block: Conv -> BatchNorm -> Conv -> BatchNorm -> Pooling -> Dropout\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape, kernel_regularizer=l2_reg))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu',  kernel_regularizer=l2_reg))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Second Convolutional Block: Conv -> BatchNorm -> Conv -> BatchNorm -> Pooling -> Dropout\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2_reg))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2_reg))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=l2_reg))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2_reg))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model using the input shape and number of classes\n",
    "model = create_model(input_shape=x_train.shape[1:], num_classes=num_classes)\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compilation\n",
    "\n",
    "In this step, we compile the CNN model. Compilation involves specifying:\n",
    "\n",
    "*   **Optimizer:** We use the `Adam` optimizer, a popular choice for deep learning models due to its efficiency and adaptive learning rates. Adam often performs well without extensive hyperparameter tuning.\n",
    "*   **Loss Function:** For multi-class classification, `categorical_crossentropy` is used as the loss function. It measures the difference between the predicted probability distribution and the true distribution.\n",
    "*   **Metrics:** We will track `accuracy` during training and evaluation to measure the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Now, we train the compiled model using the training data and validate it using the validation data. We will use callbacks to enhance the training process:\n",
    "\n",
    "*   **EarlyStopping:** This callback stops training when a monitored metric has stopped improving. We use it to prevent overfitting and save training time. It monitors validation loss and stops if it doesn't improve for a certain number of epochs (`patience`).\n",
    "*   **ModelCheckpoint:** This callback saves the best model during training based on validation accuracy. This ensures that we always have the best performing model saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks to improve training efficiency\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_datagen.flow(x_train, y_train, batch_size=64),\n",
    "                    epochs=50,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[early_stop, model_checkpoint])\n",
    "\n",
    "print(\"The training process has been completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b89969c",
   "metadata": {},
   "source": [
    "We will also visualize the training and validation accuracy and loss curves to understand the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad522a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss and accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "During the training phase, multiple candidate models were rigorously evaluated using validation metrics (e.g., loss, accuracy, and other domain-specific measures). The model with the best performance on the validation set was selected as the \"best model\" and saved for further evaluation.\n",
    "\n",
    "In this section, we demonstrate how this best model is used to evaluate performance on unseen test data. The evaluation process includes:\n",
    "\n",
    "*   **Accuracy:** The overall accuracy of the model on the test set.\n",
    "*   **Classification Report:** Includes precision, recall, F1-score, and support for each class.\n",
    "*   **Confusion Matrix:** A matrix showing the counts of true positive, true negative, false positive, and false negative predictions, broken down by class.\n",
    "\n",
    "The best model (saved as, for example, best_model.h5) is loaded and applied to the test dataset. Its performance metrics, as shown below, confirm that the model generalizes well and is robust in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model = tf.keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_labels = y_pred.argmax(axis=1)\n",
    "y_true_labels = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, tick_marks)\n",
    "plt.yticks(tick_marks, tick_marks)\n",
    "\n",
    "# Annotate the confusion matrix\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predictions\n",
    "\n",
    "In this section, we visualize the model's predictions on a few test images. The images are displayed along with both their true labels and the labels predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Select a few random test images\n",
    "num_images = 10\n",
    "indices = random.sample(range(len(x_test)), num_images)\n",
    "sample_images = x_test[indices]\n",
    "sample_true_labels = y_true_labels[indices]\n",
    "sample_pred_labels = y_pred_labels[indices]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_test[idx])\n",
    "    plt.title(f\"True: {class_names[y_true_labels[idx]]}\\nPred: {class_names[y_pred_labels[idx]]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcb045",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this project, we built and trained a Convolutional Neural Network (CNN) for image classification on the CIFAR-10 dataset using TensorFlow and Keras. The model incorporated several best practices, including:\n",
    "\n",
    "- **Data Augmentation:** Random rotations, shifts, and horizontal flips to improve generalization and reduce overfitting.\n",
    "- **L2 Regularization:** Applied to all convolutional and dense layers to penalize large weights and further prevent overfitting.\n",
    "- **Dropout:** Tuned dropout rates in both convolutional and dense layers for better regularization.\n",
    "\n",
    "**Results:**\n",
    "- Training Accuracy: 84.24%\n",
    "- Validation Accuracy: 80.34%\n",
    "- Test Accuracy: 79.75%\n",
    "- Precision, Recall, F1-Score: ~80% for all classes\n",
    "\n",
    "While the model demonstrates a solid understanding of CNN fundamentals and achieves balanced performance across all classes, there is still a gap between training and validation/test accuracy, and some overfitting is present. These results are typical for a baseline CNN on CIFAR-10 without advanced techniques.\n",
    "\n",
    "**Potential Improvements and Future Work:**\n",
    "- Experiment with deeper and more complex architectures (e.g., ResNet, VGG, EfficientNet)\n",
    "- Perform extensive hyperparameter tuning (learning rate, batch size, dropout rates, regularization strength)\n",
    "- Implement transfer learning using pre-trained models on larger datasets (e.g., ImageNet)\n",
    "- Integrate additional regularization methods (e.g., L1 regularization, data mixup)\n",
    "- Use ensemble methods to combine predictions from multiple models\n",
    "- Add TensorBoard integration for enhanced training visualization\n",
    "\n",
    "This project provides a strong foundation for further exploration in computer vision and deep learning. By iterating on these improvements, you can achieve even higher accuracy and more robust models for image classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
